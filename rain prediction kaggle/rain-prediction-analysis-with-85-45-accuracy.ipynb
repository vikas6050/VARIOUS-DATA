{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ㅤㅤㅤㅤㅤㅤㅤRain Prediction with Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"Rains are essential part of our lives. Clouds give the gift of rains to humans. Weather department tries to forecast when will it rain. So, I try to predict whether it will rain in Australia tomorrow or not.","metadata":{}},{"cell_type":"markdown","source":"Hence, in this kernel, I implement Logistic Regression with Python and Scikit-Learn and build a classifier to predict whether or not it will rain tomorrow in Australia. I train a binary classification model using Logistic Regression. I have used the Rain in Australia dataset for this project.","metadata":{}},{"cell_type":"markdown","source":"## 1. Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing\n\n# import libraries for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:21.375561Z","iopub.execute_input":"2022-03-11T11:49:21.375842Z","iopub.status.idle":"2022-03-11T11:49:22.390502Z","shell.execute_reply.started":"2022-03-11T11:49:21.37581Z","shell.execute_reply":"2022-03-11T11:49:22.389567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Import Dataset","metadata":{}},{"cell_type":"markdown","source":"The next step is to import data","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('../input/weather-dataset-rattle-package/weatherAUS.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:22.391896Z","iopub.execute_input":"2022-03-11T11:49:22.392193Z","iopub.status.idle":"2022-03-11T11:49:22.946707Z","shell.execute_reply.started":"2022-03-11T11:49:22.392163Z","shell.execute_reply":"2022-03-11T11:49:22.94595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Exploratory data analysis","metadata":{}},{"cell_type":"markdown","source":"- we have imported the data.\n- now, its time to explore the data to dain insights about it.","metadata":{}},{"cell_type":"markdown","source":"### preview the dataset","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:22.94769Z","iopub.execute_input":"2022-03-11T11:49:22.948097Z","iopub.status.idle":"2022-03-11T11:49:22.991187Z","shell.execute_reply.started":"2022-03-11T11:49:22.948061Z","shell.execute_reply":"2022-03-11T11:49:22.990636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### view dimention of dataset","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:22.992713Z","iopub.execute_input":"2022-03-11T11:49:22.993024Z","iopub.status.idle":"2022-03-11T11:49:22.998114Z","shell.execute_reply.started":"2022-03-11T11:49:22.992996Z","shell.execute_reply":"2022-03-11T11:49:22.997408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we can see that there are 145460 row and 23 columns in the dataset","metadata":{}},{"cell_type":"markdown","source":"### view column names","metadata":{}},{"cell_type":"code","source":"col_names=df.columns\ncol_names","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:22.999165Z","iopub.execute_input":"2022-03-11T11:49:22.999424Z","iopub.status.idle":"2022-03-11T11:49:23.012243Z","shell.execute_reply.started":"2022-03-11T11:49:22.999398Z","shell.execute_reply":"2022-03-11T11:49:23.01121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Drop RISK_MM variable","metadata":{}},{"cell_type":"markdown","source":"we can see that some of columns are less importand than others such as: RISK_MM \n    So, we should drop it as follow","metadata":{}},{"cell_type":"markdown","source":"### Checking For datatypes of the attributes","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:23.013716Z","iopub.execute_input":"2022-03-11T11:49:23.014098Z","iopub.status.idle":"2022-03-11T11:49:23.155714Z","shell.execute_reply.started":"2022-03-11T11:49:23.014053Z","shell.execute_reply":"2022-03-11T11:49:23.154834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"comment\n- we can see that that the dataset contains mixture of categorical and numerical variables.\n- categorical variable have data type : float64 \n- Numerical variable have data type : object \n- Also , there are missing values in data set , we are gonna explore it later","metadata":{}},{"cell_type":"markdown","source":"### View statistical properties of dataset","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:23.157091Z","iopub.execute_input":"2022-03-11T11:49:23.157488Z","iopub.status.idle":"2022-03-11T11:49:23.294816Z","shell.execute_reply.started":"2022-03-11T11:49:23.157446Z","shell.execute_reply":"2022-03-11T11:49:23.293988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. univariate Analysis","metadata":{}},{"cell_type":"markdown","source":"##### Explore Rain Tomorrow Target variable","metadata":{}},{"cell_type":"markdown","source":"#### check for missing values ","metadata":{}},{"cell_type":"code","source":"df['RainTomorrow'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:23.296088Z","iopub.execute_input":"2022-03-11T11:49:23.29634Z","iopub.status.idle":"2022-03-11T11:49:23.31871Z","shell.execute_reply.started":"2022-03-11T11:49:23.296304Z","shell.execute_reply":"2022-03-11T11:49:23.317826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we can see that there are 3267 missing values in rain tomorrow","metadata":{}},{"cell_type":"markdown","source":"#### check for the unique values","metadata":{}},{"cell_type":"code","source":"df['RainTomorrow'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:23.319734Z","iopub.execute_input":"2022-03-11T11:49:23.319935Z","iopub.status.idle":"2022-03-11T11:49:23.343847Z","shell.execute_reply.started":"2022-03-11T11:49:23.3199Z","shell.execute_reply":"2022-03-11T11:49:23.34324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### view the frequency of values ","metadata":{}},{"cell_type":"code","source":"df['RainTomorrow'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:23.346439Z","iopub.execute_input":"2022-03-11T11:49:23.346849Z","iopub.status.idle":"2022-03-11T11:49:23.376332Z","shell.execute_reply.started":"2022-03-11T11:49:23.346819Z","shell.execute_reply":"2022-03-11T11:49:23.375533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"important points to note \n- there are 3267 of missing values \n- There are 31877 predictions that it will rain\n- there are 110316 predictions that it wont rain ","metadata":{}},{"cell_type":"markdown","source":"### view percentage of frecquency values ","metadata":{}},{"cell_type":"markdown","source":"to show the precentage ,we should divided by lenght of dataset ","metadata":{}},{"cell_type":"code","source":"RainTomorrow={\"Yes\":31877,\n             'No':110316,\n             'Missing values':3267}","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:23.377584Z","iopub.execute_input":"2022-03-11T11:49:23.377894Z","iopub.status.idle":"2022-03-11T11:49:23.385423Z","shell.execute_reply.started":"2022-03-11T11:49:23.377851Z","shell.execute_reply":"2022-03-11T11:49:23.384663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print ('The precentage is :')\nfor key,value in RainTomorrow.items():\n    print(key ,':', value/len(df))","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:23.386559Z","iopub.execute_input":"2022-03-11T11:49:23.386845Z","iopub.status.idle":"2022-03-11T11:49:23.398909Z","shell.execute_reply.started":"2022-03-11T11:49:23.386804Z","shell.execute_reply":"2022-03-11T11:49:23.397922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hence\n- we can see that the total number  of raine tomorrow value : No appears 75% \n- we can see that the total number  of raine tomorrow value : Yes appears 21%\n-we can see that the total number  of raine tomorrow value : missing appears 0.2%     ","metadata":{}},{"cell_type":"markdown","source":"### Visualize frequency distribution of RainTomorrow variable","metadata":{}},{"cell_type":"code","source":"plt.ax =plt.subplots(figsize=(6,8))\nax=sns.countplot(x='RainTomorrow',data=df,palette=\"Set3\")\n#plt.xticks(rotation=90)\nplt.grid()\nplt.title('Frecquency values');","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:23.400916Z","iopub.execute_input":"2022-03-11T11:49:23.40151Z","iopub.status.idle":"2022-03-11T11:49:23.749045Z","shell.execute_reply.started":"2022-03-11T11:49:23.401464Z","shell.execute_reply":"2022-03-11T11:49:23.748362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Explore Categorical Variables","metadata":{}},{"cell_type":"markdown","source":"we should show the categorical variables from dataset","metadata":{}},{"cell_type":"code","source":"categorical= df.select_dtypes(include=['object'])\ncategorical.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:23.750605Z","iopub.execute_input":"2022-03-11T11:49:23.751161Z","iopub.status.idle":"2022-03-11T11:49:23.776959Z","shell.execute_reply.started":"2022-03-11T11:49:23.751117Z","shell.execute_reply":"2022-03-11T11:49:23.776135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" summary of categorical variables \n - There is Date variable ,it is denoted by Date columns\n - There are 6 categorical variables. These are given by Location, WindGustDir, WindDir9am, WindDir3pm, RainToday and RainTomorrow.\n - There are two binary categorical variables - RainToday and RainTomorrow\n - RainTomorrow is the target variable.","metadata":{}},{"cell_type":"markdown","source":"### Missing values in Categorical Variables","metadata":{}},{"cell_type":"code","source":"dict={}\nfor i in list(df[categorical.columns]):\n    dict[i]=df[i].isnull().sum()\npd.DataFrame(dict,index=['number of null values']).transpose() ","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:23.778519Z","iopub.execute_input":"2022-03-11T11:49:23.779035Z","iopub.status.idle":"2022-03-11T11:49:23.914242Z","shell.execute_reply.started":"2022-03-11T11:49:23.778992Z","shell.execute_reply":"2022-03-11T11:49:23.913565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Number of labels: cardinality","metadata":{}},{"cell_type":"markdown","source":">The number of labels within a categorical variable is known as cardinality. A high number of labels within a variable is known as high cardinality. High cardinality may pose some serious problems in the machine learning model. So, I will check for high cardinality.","metadata":{}},{"cell_type":"code","source":"# check for cardinality in categorical variables\n\nfor var in categorical:\n    \n    print(var, ' contains ', len(df[var].unique()), ' labels')","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:23.915695Z","iopub.execute_input":"2022-03-11T11:49:23.916142Z","iopub.status.idle":"2022-03-11T11:49:24.020067Z","shell.execute_reply.started":"2022-03-11T11:49:23.916107Z","shell.execute_reply":"2022-03-11T11:49:24.01921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that there is a Date variable which needs to be preprocessed. I will do preprocessing in the following section.\n\nAll the other variables contain relatively smaller number of variables.","metadata":{}},{"cell_type":"markdown","source":"#### Feature Engineering of Date Variable","metadata":{}},{"cell_type":"code","source":"df['Date'] = pd.to_datetime(df['Date'])","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.0214Z","iopub.execute_input":"2022-03-11T11:49:24.021644Z","iopub.status.idle":"2022-03-11T11:49:24.076142Z","shell.execute_reply.started":"2022-03-11T11:49:24.021616Z","shell.execute_reply":"2022-03-11T11:49:24.075244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we shold convert type of Date variable to datetime as can i process it \n","metadata":{}},{"cell_type":"code","source":"df['Year'] = df['Date'].dt.year\n\ndf['Month'] = df['Date'].dt.month\n\ndf['Day'] = df['Date'].dt.day","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.078416Z","iopub.execute_input":"2022-03-11T11:49:24.078803Z","iopub.status.idle":"2022-03-11T11:49:24.126893Z","shell.execute_reply.started":"2022-03-11T11:49:24.078687Z","shell.execute_reply":"2022-03-11T11:49:24.125922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" we have separated the date variable into three variables Now , we should drop date variable ","metadata":{}},{"cell_type":"code","source":"df.drop('Date',inplace= True,axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.128059Z","iopub.execute_input":"2022-03-11T11:49:24.128367Z","iopub.status.idle":"2022-03-11T11:49:24.156679Z","shell.execute_reply.started":"2022-03-11T11:49:24.128334Z","shell.execute_reply":"2022-03-11T11:49:24.156072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.157755Z","iopub.execute_input":"2022-03-11T11:49:24.158091Z","iopub.status.idle":"2022-03-11T11:49:24.185328Z","shell.execute_reply.started":"2022-03-11T11:49:24.158064Z","shell.execute_reply":"2022-03-11T11:49:24.184762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we can see that the Date variable is removed from the dataset and we should Explore Categorical data again","metadata":{}},{"cell_type":"markdown","source":"#### Explore Categorical Variables one by one ","metadata":{}},{"cell_type":"code","source":"new_categorical= df.select_dtypes(include=['object'])\nnew_categorical.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.186309Z","iopub.execute_input":"2022-03-11T11:49:24.186617Z","iopub.status.idle":"2022-03-11T11:49:24.204626Z","shell.execute_reply.started":"2022-03-11T11:49:24.186589Z","shell.execute_reply":"2022-03-11T11:49:24.203802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### check missing values in categorical variables.","metadata":{}},{"cell_type":"code","source":"new_categorical.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.205907Z","iopub.execute_input":"2022-03-11T11:49:24.208695Z","iopub.status.idle":"2022-03-11T11:49:24.306708Z","shell.execute_reply.started":"2022-03-11T11:49:24.20866Z","shell.execute_reply":"2022-03-11T11:49:24.305748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that WindGustDir, WindDir9am, WindDir3pm, RainToday variables contain missing values. I will explore these variables one by one","metadata":{}},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"in all variables :\n- i will check number of labels and show it \n- convert categorical variable into dummy/indicator variables by function is called get_dummies()","metadata":{}},{"cell_type":"markdown","source":"#### Explore Location variable","metadata":{}},{"cell_type":"code","source":"new_categorical['Location'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.30803Z","iopub.execute_input":"2022-03-11T11:49:24.308254Z","iopub.status.idle":"2022-03-11T11:49:24.328593Z","shell.execute_reply.started":"2022-03-11T11:49:24.308226Z","shell.execute_reply":"2022-03-11T11:49:24.327548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.get_dummies(df.Location, drop_first=True).head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.330509Z","iopub.execute_input":"2022-03-11T11:49:24.331115Z","iopub.status.idle":"2022-03-11T11:49:24.403586Z","shell.execute_reply.started":"2022-03-11T11:49:24.331071Z","shell.execute_reply":"2022-03-11T11:49:24.402757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Explore WindGustDir variable","metadata":{}},{"cell_type":"code","source":"new_categorical['WindGustDir'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.405058Z","iopub.execute_input":"2022-03-11T11:49:24.405555Z","iopub.status.idle":"2022-03-11T11:49:24.426551Z","shell.execute_reply.started":"2022-03-11T11:49:24.405513Z","shell.execute_reply":"2022-03-11T11:49:24.425581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.get_dummies(df.WindGustDir,drop_first=True,dummy_na=True).head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.428009Z","iopub.execute_input":"2022-03-11T11:49:24.428471Z","iopub.status.idle":"2022-03-11T11:49:24.47634Z","shell.execute_reply.started":"2022-03-11T11:49:24.428429Z","shell.execute_reply":"2022-03-11T11:49:24.475498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Explore WindDir9am variable","metadata":{}},{"cell_type":"code","source":"new_categorical['WindDir9am'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.477957Z","iopub.execute_input":"2022-03-11T11:49:24.478519Z","iopub.status.idle":"2022-03-11T11:49:24.499809Z","shell.execute_reply.started":"2022-03-11T11:49:24.478477Z","shell.execute_reply":"2022-03-11T11:49:24.499228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.get_dummies(df.WindDir9am,drop_first=True,dummy_na=True).head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.504467Z","iopub.execute_input":"2022-03-11T11:49:24.504973Z","iopub.status.idle":"2022-03-11T11:49:24.55269Z","shell.execute_reply.started":"2022-03-11T11:49:24.504942Z","shell.execute_reply":"2022-03-11T11:49:24.551693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Explore WindDir3pm variable","metadata":{}},{"cell_type":"code","source":"new_categorical['WindDir3pm'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.553907Z","iopub.execute_input":"2022-03-11T11:49:24.554117Z","iopub.status.idle":"2022-03-11T11:49:24.574549Z","shell.execute_reply.started":"2022-03-11T11:49:24.554091Z","shell.execute_reply":"2022-03-11T11:49:24.573583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.get_dummies(df.WindDir3pm,drop_first=True,dummy_na=True).head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.575855Z","iopub.execute_input":"2022-03-11T11:49:24.576403Z","iopub.status.idle":"2022-03-11T11:49:24.63078Z","shell.execute_reply.started":"2022-03-11T11:49:24.576358Z","shell.execute_reply":"2022-03-11T11:49:24.630005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Explore RainToday variable","metadata":{}},{"cell_type":"code","source":"new_categorical['RainToday'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.632179Z","iopub.execute_input":"2022-03-11T11:49:24.632404Z","iopub.status.idle":"2022-03-11T11:49:24.655237Z","shell.execute_reply.started":"2022-03-11T11:49:24.632377Z","shell.execute_reply":"2022-03-11T11:49:24.654494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.RainToday.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.65648Z","iopub.execute_input":"2022-03-11T11:49:24.65668Z","iopub.status.idle":"2022-03-11T11:49:24.684377Z","shell.execute_reply.started":"2022-03-11T11:49:24.656654Z","shell.execute_reply":"2022-03-11T11:49:24.683685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.get_dummies(df.RainToday,drop_first=True,dummy_na=True).head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.685608Z","iopub.execute_input":"2022-03-11T11:49:24.685837Z","iopub.status.idle":"2022-03-11T11:49:24.720887Z","shell.execute_reply.started":"2022-03-11T11:49:24.685809Z","shell.execute_reply":"2022-03-11T11:49:24.719919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Explore Numerical Variables ","metadata":{}},{"cell_type":"code","source":"Numerical= df.select_dtypes(include=['float64','int'])\nNumerical.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.722437Z","iopub.execute_input":"2022-03-11T11:49:24.722775Z","iopub.status.idle":"2022-03-11T11:49:24.767256Z","shell.execute_reply.started":"2022-03-11T11:49:24.722729Z","shell.execute_reply":"2022-03-11T11:49:24.766357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Numerical.columns","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.768448Z","iopub.execute_input":"2022-03-11T11:49:24.768737Z","iopub.status.idle":"2022-03-11T11:49:24.774914Z","shell.execute_reply.started":"2022-03-11T11:49:24.768706Z","shell.execute_reply":"2022-03-11T11:49:24.774092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Missing values in numerical variables","metadata":{}},{"cell_type":"code","source":"Numerical.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.776445Z","iopub.execute_input":"2022-03-11T11:49:24.77732Z","iopub.status.idle":"2022-03-11T11:49:24.796911Z","shell.execute_reply.started":"2022-03-11T11:49:24.777248Z","shell.execute_reply":"2022-03-11T11:49:24.795568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check summary statistics","metadata":{}},{"cell_type":"code","source":"Numerical.describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.79858Z","iopub.execute_input":"2022-03-11T11:49:24.799529Z","iopub.status.idle":"2022-03-11T11:49:24.977943Z","shell.execute_reply.started":"2022-03-11T11:49:24.799484Z","shell.execute_reply":"2022-03-11T11:49:24.977364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On closer inspection, we can see that the Rainfall, Evaporation, WindSpeed9am and WindSpeed3pm columns may contain outliers.\n\nI will draw boxplots to visualise outliers in the above variables.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\n\n\nplt.subplot(2, 2, 1)\nfig = df.boxplot(column='Rainfall')\nfig.set_title('')\nfig.set_ylabel('Rainfall')\n\n\nplt.subplot(2, 2, 2)\nfig = df.boxplot(column='Evaporation')\nfig.set_title('')\nfig.set_ylabel('Evaporation')\n\n\nplt.subplot(2, 2, 3)\nfig = df.boxplot(column='WindSpeed9am')\nfig.set_title('')\nfig.set_ylabel('WindSpeed9am')\n\n\nplt.subplot(2, 2, 4)\nfig = df.boxplot(column='WindSpeed3pm')\nfig.set_title('')\nfig.set_ylabel('WindSpeed3pm')","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:24.978809Z","iopub.execute_input":"2022-03-11T11:49:24.979508Z","iopub.status.idle":"2022-03-11T11:49:26.359867Z","shell.execute_reply.started":"2022-03-11T11:49:24.979458Z","shell.execute_reply":"2022-03-11T11:49:26.35907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Find all  outliers","metadata":{}},{"cell_type":"code","source":"# find outliers for Rainfall variable\nIQR = df.Rainfall.quantile(0.75) - df.Rainfall.quantile(0.25)\nLower_fence = df.Rainfall.quantile(0.25) - (IQR * 1.5)\nUpper_fence = df.Rainfall.quantile(0.75) + (IQR * 1.5)\nprint('Rainfall outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))\n\n# find outliers for Evaporation variable\n\nIQR = df.Evaporation.quantile(0.75) - df.Evaporation.quantile(0.25)\nLower_fence = df.Evaporation.quantile(0.25) - (IQR * 1.5)\nUpper_fence = df.Evaporation.quantile(0.75) + (IQR * 1.5)\nprint('Evaporation outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))\n\n# find outliers for WindSpeed9am variable\n\nIQR = df.WindSpeed9am.quantile(0.75) - df.WindSpeed9am.quantile(0.25)\nLower_fence = df.WindSpeed9am.quantile(0.25) - (IQR * 1.5)\nUpper_fence = df.WindSpeed9am.quantile(0.75) + (IQR * 1.5)\nprint('WindSpeed9am outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))\n\n# find outliers for WindSpeed3pm variable\n\nIQR = df.WindSpeed3pm.quantile(0.75) - df.WindSpeed3pm.quantile(0.25)\nLower_fence = df.WindSpeed3pm.quantile(0.25) - (IQR * 1.5)\nUpper_fence = df.WindSpeed3pm.quantile(0.75) + (IQR * 1.5)\nprint('WindSpeed3pm outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:26.360921Z","iopub.execute_input":"2022-03-11T11:49:26.36114Z","iopub.status.idle":"2022-03-11T11:49:26.419868Z","shell.execute_reply.started":"2022-03-11T11:49:26.361111Z","shell.execute_reply":"2022-03-11T11:49:26.419268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"important point to note :\n- For Rainfall, the minimum and maximum values are 0.0 and 371.0. So, the outliers are values > 2.0\n- For Evaporation, the minimum and maximum values are 0.0 and 145.0. So, the outliers are values > 14.6\n- For WindSpeed9am, the minimum and maximum values are 0.0 and 130.0. So, the outliers are values > 37\n- For WindSpeed3pm, the minimum and maximum values are 0.0 and 87.0. So, the outliers are values > 40.5","metadata":{}},{"cell_type":"markdown","source":"************","metadata":{}},{"cell_type":"markdown","source":"## 5.Multivariate Analysis ","metadata":{}},{"cell_type":"markdown","source":"> An important step in EDA is to discover patterns and relationships between variables in the dataset.\n\n>I will use heat map and pair plot to discover the patterns and relationships in the dataset.\n\n>First of all, I will draw a heat map.","metadata":{}},{"cell_type":"code","source":"correlation = df.corr()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:26.421236Z","iopub.execute_input":"2022-03-11T11:49:26.421727Z","iopub.status.idle":"2022-03-11T11:49:26.571619Z","shell.execute_reply.started":"2022-03-11T11:49:26.421682Z","shell.execute_reply":"2022-03-11T11:49:26.570979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,12))\nplt.title('Correlation Heatmap of Rain in Australia Dataset')\nax = sns.heatmap(correlation, square=True, annot=True, fmt='.2f', linecolor='white')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nax.set_yticklabels(ax.get_yticklabels(), rotation=30)           \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:26.573019Z","iopub.execute_input":"2022-03-11T11:49:26.573535Z","iopub.status.idle":"2022-03-11T11:49:28.36726Z","shell.execute_reply.started":"2022-03-11T11:49:26.57349Z","shell.execute_reply":"2022-03-11T11:49:28.366418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Interpretation\n\n- From the above correlation heat map, we can conclude that :-\n\n\n- MinTemp and MaxTemp variables are highly positively correlated (correlation coefficient = 0.74).\n\n\n- MinTemp and Temp3pm variables are also highly positively correlated (correlation coefficient = 0.71).\n\n\n- MinTemp and Temp9am variables are strongly positively correlated (correlation coefficient = 0.90).\n\n\n- MaxTemp and Temp9am variables are strongly positively correlated (correlation coefficient = 0.89).\n\n\n- MaxTemp and Temp3pm variables are also strongly positively correlated (correlation coefficient = 0.98).\n\n\n- WindGustSpeed and WindSpeed3pm variables are highly positively correlated (correlation coefficient = 0.69).\n\n\n- Pressure9am and Pressure3pm variables are strongly positively correlated (correlation coefficient = 0.96).\n\n\n- Temp9am and Temp3pm variables are strongly positively correlated (correlation coefficient = 0.86)","metadata":{}},{"cell_type":"markdown","source":"# ㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤData Modeling","metadata":{}},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"### 6. Declare feature vector and target variable","metadata":{}},{"cell_type":"code","source":"X = df.drop(['RainTomorrow'], axis=1)\n\ny = df['RainTomorrow']","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:28.368846Z","iopub.execute_input":"2022-03-11T11:49:28.369312Z","iopub.status.idle":"2022-03-11T11:49:28.388457Z","shell.execute_reply.started":"2022-03-11T11:49:28.369253Z","shell.execute_reply":"2022-03-11T11:49:28.387414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7.Split data into separate training and test set","metadata":{}},{"cell_type":"code","source":"# split X and y into training and testing sets\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:28.390225Z","iopub.execute_input":"2022-03-11T11:49:28.390748Z","iopub.status.idle":"2022-03-11T11:49:28.629233Z","shell.execute_reply.started":"2022-03-11T11:49:28.3907Z","shell.execute_reply":"2022-03-11T11:49:28.628336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:28.630801Z","iopub.execute_input":"2022-03-11T11:49:28.631556Z","iopub.status.idle":"2022-03-11T11:49:28.639632Z","shell.execute_reply.started":"2022-03-11T11:49:28.631502Z","shell.execute_reply":"2022-03-11T11:49:28.638632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 8. Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"**Feature Engineering** is the process of transforming raw data into useful features that help us to understand our model better and increase its predictive power. I will carry out feature engineering on different types of variables.\n\nFirst, I will display the categorical and numerical variables again separately.","metadata":{}},{"cell_type":"code","source":"# display categorical variables\n\ncategorical = [col for col in X_train.columns if X_train[col].dtypes == 'O']\n\ncategorical","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:28.641271Z","iopub.execute_input":"2022-03-11T11:49:28.641773Z","iopub.status.idle":"2022-03-11T11:49:28.654341Z","shell.execute_reply.started":"2022-03-11T11:49:28.641737Z","shell.execute_reply":"2022-03-11T11:49:28.653618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display numerical variables\n\nnumerical = [col for col in X_train.columns if X_train[col].dtypes != 'O']\n\nnumerical","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:28.657275Z","iopub.execute_input":"2022-03-11T11:49:28.657721Z","iopub.status.idle":"2022-03-11T11:49:28.663458Z","shell.execute_reply.started":"2022-03-11T11:49:28.65769Z","shell.execute_reply":"2022-03-11T11:49:28.662708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### missing values in numerical variables","metadata":{}},{"cell_type":"code","source":"# check missing values in numerical variables in X_train\n\nX_train[numerical].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:28.664578Z","iopub.execute_input":"2022-03-11T11:49:28.665203Z","iopub.status.idle":"2022-03-11T11:49:28.697262Z","shell.execute_reply.started":"2022-03-11T11:49:28.665173Z","shell.execute_reply":"2022-03-11T11:49:28.696429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check missing values in numerical variables in X_test\n\nX_test[numerical].isnull().sum()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-03-11T11:49:28.698659Z","iopub.execute_input":"2022-03-11T11:49:28.699053Z","iopub.status.idle":"2022-03-11T11:49:28.712459Z","shell.execute_reply.started":"2022-03-11T11:49:28.699011Z","shell.execute_reply":"2022-03-11T11:49:28.711431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# impute missing values in X_train and X_test with respective column median in X_train\n\nfor df1 in [X_train, X_test]:\n    for col in numerical:\n        col_median=X_train[col].median()\n        df1[col].fillna(col_median, inplace=True) ","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:28.713439Z","iopub.execute_input":"2022-03-11T11:49:28.71393Z","iopub.status.idle":"2022-03-11T11:49:28.795256Z","shell.execute_reply.started":"2022-03-11T11:49:28.713893Z","shell.execute_reply":"2022-03-11T11:49:28.794343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check again missing values in numerical variables in X_train\n\nX_train[numerical].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:28.79648Z","iopub.execute_input":"2022-03-11T11:49:28.796718Z","iopub.status.idle":"2022-03-11T11:49:28.812198Z","shell.execute_reply.started":"2022-03-11T11:49:28.796689Z","shell.execute_reply":"2022-03-11T11:49:28.811617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# impute missing categorical variables with most frequent value\n\nfor df2 in [X_train, X_test]:\n    df2['WindGustDir'].fillna(X_train['WindGustDir'].mode()[0], inplace=True)\n    df2['WindDir9am'].fillna(X_train['WindDir9am'].mode()[0], inplace=True)\n    df2['WindDir3pm'].fillna(X_train['WindDir3pm'].mode()[0], inplace=True)\n    df2['RainToday'].fillna(X_train['RainToday'].mode()[0], inplace=True)\ny_train.fillna(y_train.mode()[0], inplace=True)\ny_test.fillna(y_test.mode()[0], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:28.813381Z","iopub.execute_input":"2022-03-11T11:49:28.813968Z","iopub.status.idle":"2022-03-11T11:49:29.062954Z","shell.execute_reply.started":"2022-03-11T11:49:28.813927Z","shell.execute_reply":"2022-03-11T11:49:29.062044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check missing values in categorical variables in X_train\n\nX_train[categorical].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:29.06427Z","iopub.execute_input":"2022-03-11T11:49:29.064525Z","iopub.status.idle":"2022-03-11T11:49:29.139832Z","shell.execute_reply.started":"2022-03-11T11:49:29.064495Z","shell.execute_reply":"2022-03-11T11:49:29.139076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:29.14108Z","iopub.execute_input":"2022-03-11T11:49:29.1414Z","iopub.status.idle":"2022-03-11T11:49:29.215234Z","shell.execute_reply.started":"2022-03-11T11:49:29.141365Z","shell.execute_reply":"2022-03-11T11:49:29.214375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Engineering outliers in numerical variables ","metadata":{}},{"cell_type":"markdown","source":"We have seen that the Rainfall, Evaporation, WindSpeed9am and WindSpeed3pm columns contain outliers. I will use top-coding approach to cap maximum values and remove outliers from the above variables.","metadata":{}},{"cell_type":"code","source":"import numpy as np\ndef max_value(df3, variable, top):\n    return np.where(df3[variable]>top, top, df3[variable])\n\n\n    X_train['Rainfall'] = max_value(X_train, 'Rainfall', 2)\n    X_train['Evaporation'] = max_value(X_train, 'Evaporation', 14.6)\n    X_train['WindSpeed9am'] = max_value(X_train, 'WindSpeed9am', 37)\n    X_train['WindSpeed3pm'] = max_value(X_train, 'WindSpeed3pm', 40.5)\n    \n    X_test['Rainfall'] = max_value(X_test, 'Rainfall', 2)\n    X_test['Evaporation'] = max_value(X_test, 'Evaporation', 14.6)\n    X_test['WindSpeed9am'] = max_value(X_test, 'WindSpeed9am', 37)\n    X_test['WindSpeed3pm'] = max_value(X_test, 'WindSpeed3pm', 40.5)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:29.21633Z","iopub.execute_input":"2022-03-11T11:49:29.21655Z","iopub.status.idle":"2022-03-11T11:49:29.223744Z","shell.execute_reply.started":"2022-03-11T11:49:29.216523Z","shell.execute_reply":"2022-03-11T11:49:29.223092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Encode categorical variables","metadata":{}},{"cell_type":"code","source":"X_train[categorical].head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:29.224721Z","iopub.execute_input":"2022-03-11T11:49:29.225322Z","iopub.status.idle":"2022-03-11T11:49:29.252952Z","shell.execute_reply.started":"2022-03-11T11:49:29.225257Z","shell.execute_reply":"2022-03-11T11:49:29.252366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import category_encoders as ce\n\nencoder = ce.BinaryEncoder(cols=['RainToday'])\n\nX_train = encoder.fit_transform(X_train)\n\nX_test = encoder.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:29.253832Z","iopub.execute_input":"2022-03-11T11:49:29.254612Z","iopub.status.idle":"2022-03-11T11:49:29.743561Z","shell.execute_reply.started":"2022-03-11T11:49:29.25456Z","shell.execute_reply":"2022-03-11T11:49:29.742677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:29.744531Z","iopub.execute_input":"2022-03-11T11:49:29.744749Z","iopub.status.idle":"2022-03-11T11:49:29.77576Z","shell.execute_reply.started":"2022-03-11T11:49:29.744722Z","shell.execute_reply":"2022-03-11T11:49:29.774803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that two additional variables RainToday_0 and RainToday_1 are created from RainToday variable.\n\nNow, I will create the X_train training set.","metadata":{}},{"cell_type":"code","source":"X_train = pd.concat([X_train[numerical], X_train[['RainToday_0', 'RainToday_1']],\n                     pd.get_dummies(X_train.Location), \n                     pd.get_dummies(X_train.WindGustDir),\n                     pd.get_dummies(X_train.WindDir9am),\n                     pd.get_dummies(X_train.WindDir3pm)], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:29.777109Z","iopub.execute_input":"2022-03-11T11:49:29.777825Z","iopub.status.idle":"2022-03-11T11:49:29.903632Z","shell.execute_reply.started":"2022-03-11T11:49:29.777776Z","shell.execute_reply":"2022-03-11T11:49:29.902798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:29.904759Z","iopub.execute_input":"2022-03-11T11:49:29.905058Z","iopub.status.idle":"2022-03-11T11:49:29.934106Z","shell.execute_reply.started":"2022-03-11T11:49:29.905029Z","shell.execute_reply":"2022-03-11T11:49:29.933326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Similarly, I will create the X_test testing set.","metadata":{}},{"cell_type":"code","source":"X_test = pd.concat([X_test[numerical], X_test[['RainToday_0', 'RainToday_1']],\n                     pd.get_dummies(X_test.Location), \n                     pd.get_dummies(X_test.WindGustDir),\n                     pd.get_dummies(X_test.WindDir9am),\n                     pd.get_dummies(X_test.WindDir3pm)], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:29.935319Z","iopub.execute_input":"2022-03-11T11:49:29.935568Z","iopub.status.idle":"2022-03-11T11:49:29.975503Z","shell.execute_reply.started":"2022-03-11T11:49:29.935537Z","shell.execute_reply":"2022-03-11T11:49:29.974844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now have training and testing set ready for model building. Before that, we should map all the feature variables onto the same scale. It is called feature scaling. I will do it as follows.","metadata":{}},{"cell_type":"code","source":"X_train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:29.976514Z","iopub.execute_input":"2022-03-11T11:49:29.977196Z","iopub.status.idle":"2022-03-11T11:49:30.472756Z","shell.execute_reply.started":"2022-03-11T11:49:29.97716Z","shell.execute_reply":"2022-03-11T11:49:30.471941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9.Feature Scaling ","metadata":{}},{"cell_type":"code","source":"cols = X_train.columns\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\n\nX_train = scaler.fit_transform(X_train)\n\nX_test = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:30.474262Z","iopub.execute_input":"2022-03-11T11:49:30.474754Z","iopub.status.idle":"2022-03-11T11:49:30.687728Z","shell.execute_reply.started":"2022-03-11T11:49:30.474723Z","shell.execute_reply":"2022-03-11T11:49:30.686843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = pd.DataFrame(X_train, columns=[cols])\n\nX_test = pd.DataFrame(X_test, columns=[cols])","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:30.688923Z","iopub.execute_input":"2022-03-11T11:49:30.689136Z","iopub.status.idle":"2022-03-11T11:49:30.695924Z","shell.execute_reply.started":"2022-03-11T11:49:30.689108Z","shell.execute_reply":"2022-03-11T11:49:30.695184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:30.697138Z","iopub.execute_input":"2022-03-11T11:49:30.697492Z","iopub.status.idle":"2022-03-11T11:49:31.323092Z","shell.execute_reply.started":"2022-03-11T11:49:30.697459Z","shell.execute_reply":"2022-03-11T11:49:31.322308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now have X_train dataset ready to be fed into the Logistic Regression classifier. I will do it as follows.","metadata":{}},{"cell_type":"markdown","source":"## 10.Model training","metadata":{}},{"cell_type":"code","source":"# train a logistic regression model on the training set\nfrom sklearn.linear_model import LogisticRegression\n\n\n# instantiate the model\nlogreg = LogisticRegression(solver='liblinear', random_state=0)\n\n\n# fit the model\nlogreg.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:31.324531Z","iopub.execute_input":"2022-03-11T11:49:31.324921Z","iopub.status.idle":"2022-03-11T11:49:34.209081Z","shell.execute_reply.started":"2022-03-11T11:49:31.324886Z","shell.execute_reply":"2022-03-11T11:49:34.208273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 11.Predict results","metadata":{}},{"cell_type":"code","source":"y_pred_test = logreg.predict(X_test)\n\ny_pred_test","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:34.210366Z","iopub.execute_input":"2022-03-11T11:49:34.210665Z","iopub.status.idle":"2022-03-11T11:49:34.228162Z","shell.execute_reply.started":"2022-03-11T11:49:34.210622Z","shell.execute_reply":"2022-03-11T11:49:34.227143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**predict_proba method**\n\n**predict_proba** method gives the probabilities for the target variable(0 and 1) in this case, in array form.\n\n0 is for probability of no rain and 1 is for probability of rain.","metadata":{}},{"cell_type":"code","source":"# probability of getting output as 0 - no rain\n\nlogreg.predict_proba(X_test)[:,0]","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:34.229839Z","iopub.execute_input":"2022-03-11T11:49:34.230859Z","iopub.status.idle":"2022-03-11T11:49:34.250669Z","shell.execute_reply.started":"2022-03-11T11:49:34.230807Z","shell.execute_reply":"2022-03-11T11:49:34.24961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #probability of getting output as 1 - rain\n\nlogreg.predict_proba(X_test)[:,1]","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:34.252337Z","iopub.execute_input":"2022-03-11T11:49:34.252737Z","iopub.status.idle":"2022-03-11T11:49:34.271896Z","shell.execute_reply.started":"2022-03-11T11:49:34.252683Z","shell.execute_reply":"2022-03-11T11:49:34.270859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 12.Check accuracy score ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nprint('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:34.276496Z","iopub.execute_input":"2022-03-11T11:49:34.276849Z","iopub.status.idle":"2022-03-11T11:49:34.45999Z","shell.execute_reply.started":"2022-03-11T11:49:34.276806Z","shell.execute_reply":"2022-03-11T11:49:34.458666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### RandomForest Model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n#rf_params = {'n_estimators':[100,150,200],'criterion':['gini','entropy'],}\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_pred_test=rf.predict(X_test)\nprint('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:49:34.461364Z","iopub.execute_input":"2022-03-11T11:49:34.464285Z","iopub.status.idle":"2022-03-11T11:50:07.154649Z","shell.execute_reply.started":"2022-03-11T11:49:34.464248Z","shell.execute_reply":"2022-03-11T11:50:07.153791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### AdaBoost Model","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\nrf = AdaBoostClassifier()\nrf.fit(X_train, y_train)\ny_pred_test=rf.predict(X_test)\nprint('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:50:07.15603Z","iopub.execute_input":"2022-03-11T11:50:07.156349Z","iopub.status.idle":"2022-03-11T11:50:36.726442Z","shell.execute_reply.started":"2022-03-11T11:50:07.156285Z","shell.execute_reply":"2022-03-11T11:50:36.72584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Accuracy with Models :**\n1. - **LogisticRegression** is : 84.76%\n2. - **RandomForestClassifier** : 85.39%\n3. - **AdaBoostClassifier** :   84.24 %","metadata":{}},{"cell_type":"markdown","source":"## 13.Confusion matrix ","metadata":{}},{"cell_type":"markdown","source":"A confusion matrix is a tool for summarizing the performance of a classification algorithm. A confusion matrix will give us a clear picture of classification model performance and the types of errors produced by the model. It gives us a summary of correct and incorrect predictions broken down by each category. The summary is represented in a tabular form.\n\nFour types of outcomes are possible while evaluating a classification model performance. These four outcomes are described below:-\n\n**True Positives (TP)** – True Positives occur when we predict an observation belongs to a certain class and the observation actually belongs to that class.\n\n**True Negatives (TN)** – True Negatives occur when we predict an observation does not belong to a certain class and the observation actually does not belong to that class.\n\n**False Positives (FP)** – False Positives occur when we predict an observation belongs to a certain class but the observation actually does not belong to that class. This type of error is called **Type I error**.\n\n**False Negatives (FN)** – False Negatives occur when we predict an observation does not belong to a certain class but the observation actually belongs to that class. This is a very serious error and it is called **Type II error**.\n\nThese four outcomes are summarized in a confusion matrix given below.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncm=confusion_matrix(y_test, y_pred_test)\n\nprint('Confusion matrix\\n\\n', cm)\n\nprint('\\nTrue Positives(TP) = ', cm[0,0])\n\nprint('\\nTrue Negatives(TN) = ', cm[1,1])\n\nprint('\\nFalse Positives(FP) = ', cm[0,1])\n\nprint('\\nFalse Negatives(FN) = ', cm[1,0])","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:50:36.727487Z","iopub.execute_input":"2022-03-11T11:50:36.728077Z","iopub.status.idle":"2022-03-11T11:50:37.003624Z","shell.execute_reply.started":"2022-03-11T11:50:36.728047Z","shell.execute_reply":"2022-03-11T11:50:37.002944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The confusion matrix shows 21542 + 3115 = 24657 correct predictions and 1184 + 3251 = 4435 incorrect predictions.\n\nIn this case, we have\n\n- True Positives (Actual Positive:1 and Predict Positive:1) - 21542\n\n- True Negatives (Actual Negative:0 and Predict Negative:0) - 3115\n\n- False Positives (Actual Negative:0 but Predict Positive:1) - 1184 (Type I error)\n\n- False Negatives (Actual Positive:1 but Predict Negative:0) - 3251 (Type II error)","metadata":{}},{"cell_type":"code","source":"cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n                                 index=['Predict Positive:1', 'Predict Negative:0'])\ncm_matrix.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:50:37.004699Z","iopub.execute_input":"2022-03-11T11:50:37.005357Z","iopub.status.idle":"2022-03-11T11:50:37.014742Z","shell.execute_reply.started":"2022-03-11T11:50:37.005312Z","shell.execute_reply":"2022-03-11T11:50:37.014146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu');","metadata":{"execution":{"iopub.status.busy":"2022-03-11T11:50:37.015933Z","iopub.execute_input":"2022-03-11T11:50:37.01613Z","iopub.status.idle":"2022-03-11T11:50:37.226792Z","shell.execute_reply.started":"2022-03-11T11:50:37.016105Z","shell.execute_reply":"2022-03-11T11:50:37.226235Z"},"trusted":true},"execution_count":null,"outputs":[]}]}